{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near State-of-the-Art results at Object Recognition\n",
    "\n",
    "In this project, we will be deploying a convolutional neural network (CNN) for object recognition. More specifically, we will be using the All-CNN network published in the 2015 ICLR paper, \"Striving For Simplicity: The All Convolutional Net\".  This paper can be found at the following link:\n",
    "\n",
    "https://arxiv.org/pdf/1412.6806.pdf\n",
    "\n",
    "This convolutional neural network obtained state-of-the-art performance at object recognition on the CIFAR-10 image dataset in 2015. We will build this model using Keras, a high-level neural network application programming interface (API) that supports both Theano and Tensorflow backends. You can use either backend; however, I will be using Theano.  \n",
    "\n",
    "In this project, we will learn to:\n",
    "* Import datasets from Keras\n",
    "* Use one-hot vectors for categorical labels\n",
    "* Addlayers to a Keras model\n",
    "* Load pre-trained weights\n",
    "* Make predictions using a trained Keras model\n",
    "\n",
    "The dataset we will be using is the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "### 1. Loading the Data\n",
    "\n",
    "Let's dive right in! In these first few cells, we will import necessary packages, load the dataset, and plot some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaid/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load necessary packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: (50000, 32, 32, 3)\n",
      "Testing Images: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Lets determine the dataset characteristics\n",
    "print('Training Images: {}'.format(X_train.shape))\n",
    "print('Testing Images: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Now for a single image \n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the dataset\n",
    "\n",
    "First things first, we need to preprocess the dataset so the images and labels are in a form that Keras can ingest. To start, we'll define a NumPy seed for reproducibility, then normalize the images. \n",
    "\n",
    "Furthermore, we will also convert our class labels to one-hot vectors.  This is a standard output format for neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a convolutional neural network for object recognition on CIFAR-10\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 6\n",
    "np.random.seed(seed) \n",
    "\n",
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize the inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "# class labels shape\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels are a single integer value (0-9).  What we really want is a one-hot vector of length ten.  For example, the class label of 6 should be denoted [0, 0, 0, 0, 0, 0, 1, 0, 0, 0].  We can accomplish this using the np_utils.to_categorical() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# hot encode outputs\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = Y_test.shape[1]\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the All-CNN\n",
    "\n",
    "Using the paper as a reference, we can implement the All-CNN network in Keras.  Keras models are built by simply adding layers, one after another. \n",
    "\n",
    "To make things easier for us later, we will wrap this model in a function, which will allow us to quickly and neatly generate the model later on in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start building the model - import necessary layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def allcnn(weights=None):\n",
    "    # define model type - Sequential\n",
    "    model = Sequential()\n",
    "\n",
    "    # add model layers - Convolution2D, Activation, Dropout\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same', input_shape=(32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same', strides = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same', strides = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (1, 1), padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(10, (1, 1), padding = 'valid'))\n",
    "\n",
    "    # add GlobalAveragePooling2D layer with Softmax activation\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # load the weights\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    # return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining Parameters and Training the Model\n",
    "\n",
    "We're all set! We are ready to start training our network.  In the following cells, we will define our hyper parameters, such as learning rate and momentum, define an optimizer, compile the model, and fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/350\n",
      "10080/50000 [=====>........................] - ETA: 18:40 - loss: 2.2959 - acc: 0.1093"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6ef3dfcb4ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define hyper parameters\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# build model \n",
    "model = allcnn()\n",
    "\n",
    "# define optimizer and compile model\n",
    "sgd = SGD(lr=learning_rate, decay=weight_decay, momentum=momentum, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "print (model.summary())\n",
    "\n",
    "# define additional training parameters\n",
    "epochs = 350\n",
    "batch_size = 32\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Woah, that's a long time...\n",
    "\n",
    "Uh oh. It's apparent that training this deep convolutional neural network is going to take a long time, which is not surprising considering the network has about 1.3 million parameters. Updating this many parameters takes a considerable amount of time; unless, of course, you are using a Graphics Processing Unit (GPU). This is a good time for a quick lesson on the differences between CPUs and GPUs.  \n",
    "\n",
    "The **central processing unit (CPU)** is often called the brains of the PC because it handles the majority of necessary computations. All computers have a CPU and this is what Keras and Theano automatically utilize. \n",
    "\n",
    "The **graphics processing unit (GPU)** is in charge of image rendering.  The most advanced GPUs were originally designed for gamers; however, GPU-accelerated computing, the use of a GPU together with a CPU to accelarate deep learing, analytics, and engineering applications, has become increasingly common.  In fact, the training of deep neural networks is not realistic without them. \n",
    "\n",
    "The most common GPUs for deep learning are produced by NVIDIA.  Furthermore, the NVIDIA Deep Learning SDK provides high-performance tools and libraries to power GPU-accelerated machine learning applications. An alternative would be an AMD GPU in combination with the OpenCL libraries; however, these libraries have fewer active users and less support than the NVIDIA libraries. \n",
    "\n",
    "If your computer has an NVIDIA GPU, installing the CUDA Drivers and CUDA Tookit from NVIDIA will allow Theano and Keras to utilize GPU-accelerated computing. The original paper mentions that it took approximately 10 hours to train the All-CNN network for 350 epochs using a modern GPU, which is considerably faster (several orders of magnitude) than it would take to train on CPU. \n",
    "\n",
    "If you haven't already, stop the cell above. In the following cells, we'll save some time by loading pre-trained weights for the All-CNN network. Using these weights, we can evaluate the performance of the All-CNN network on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "10000/10000 [==============================] - 84s 8ms/step\n",
      "Accuracy: 90.88%\n"
     ]
    }
   ],
   "source": [
    "# define hyper parameters\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# define weights and build model\n",
    "weights = 'all_cnn_weights_0.9088_0.4994.hdf5'\n",
    "model = allcnn(weights)\n",
    "\n",
    "# define optimizer and compile model\n",
    "sgd = SGD(lr=learning_rate, decay=weight_decay, momentum=momentum, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "print (model.summary())\n",
    "\n",
    "# test the model with pretrained weights\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Making Predictions\n",
    "\n",
    "Using the pretrained weights, we were able to achieve an accuracy of nearly 90 percent! Let's leverage this network to make some predictions. To start, we will generate a dictionary of class labels and names by referencing the website for the CIFAR-10 dataset:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Next, we'll make predictions on nine images and compare the results to the ground-truth labels.  Furthermore, we will plot the images for visual reference, this is object recognition after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "9/9 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# make dictionary of class labels and names\n",
    "classes = range(0,10)\n",
    "\n",
    "names = ['airplane',\n",
    "        'automobile',\n",
    "        'bird',\n",
    "        'cat',\n",
    "        'deer',\n",
    "        'dog',\n",
    "        'frog',\n",
    "        'horse',\n",
    "        'ship',\n",
    "        'truck']\n",
    "\n",
    "# zip the names and classes to make a dictionary of class_labels\n",
    "class_labels = dict(zip(classes, names))\n",
    "\n",
    "# generate batch of 9 images to predict\n",
    "batch = X_test[100:109]\n",
    "labels = np.argmax(Y_test[100:109],axis=-1)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(batch, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.56472342e-18 1.05810246e-20 1.89232421e-10 2.14114854e-11\n",
      "  9.99999285e-01 2.80375247e-07 3.14786662e-13 4.23812452e-07\n",
      "  1.36995572e-19 1.20971122e-18]\n",
      " [2.11912264e-16 2.03867016e-17 1.56727065e-09 5.35816639e-07\n",
      "  1.62562644e-10 9.99999404e-01 1.67125547e-09 2.07823074e-08\n",
      "  3.65486119e-15 3.51288651e-16]\n",
      " [1.27203225e-30 5.02736423e-28 5.15396277e-24 3.60512695e-21\n",
      "  1.08752228e-27 8.15215322e-22 1.00000000e+00 1.10509080e-27\n",
      "  6.19246192e-32 1.22743333e-23]\n",
      " [1.51438294e-16 4.76690539e-18 2.25836949e-09 1.00000000e+00\n",
      "  4.34811284e-11 1.68841135e-12 4.53171246e-13 2.66869536e-16\n",
      "  7.26597001e-19 6.20504176e-17]\n",
      " [8.24998297e-36 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.35651890e-36\n",
      "  8.68659706e-30 8.21906932e-22]\n",
      " [5.96992736e-24 1.00000000e+00 7.54846902e-27 8.02280708e-27\n",
      "  1.97139506e-30 2.73385063e-29 7.21873855e-31 5.56797325e-27\n",
      "  1.61868680e-26 1.19061282e-13]\n",
      " [6.45635478e-18 2.96424244e-20 1.00464758e-11 9.99999881e-01\n",
      "  6.01552066e-13 9.11104578e-08 7.88743376e-12 1.16087009e-15\n",
      "  7.85877643e-21 8.54759250e-21]\n",
      " [1.66711520e-27 7.76320857e-24 5.14038596e-20 7.23866829e-18\n",
      "  2.65794982e-21 1.44404203e-24 1.00000000e+00 4.44152956e-27\n",
      "  6.77591273e-26 9.29662637e-24]\n",
      " [4.17356525e-25 4.33874981e-23 1.77925093e-27 2.91175471e-23\n",
      "  1.00906176e-24 3.12951506e-20 1.04254110e-21 2.77667023e-21\n",
      "  1.00000000e+00 2.10683519e-28]]\n"
     ]
    }
   ],
   "source": [
    "# print our predictions\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.99999994\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# these are individual class probabilities, should sum to 1.0 (100%)\n",
    "for image in predictions:\n",
    "    print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6 3 1 1 3 6 8]\n"
     ]
    }
   ],
   "source": [
    "# use np.argmax() to convert class probabilities to class labels\n",
    "class_result = np.argmax(predictions,axis=-1)\n",
    "print (class_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
